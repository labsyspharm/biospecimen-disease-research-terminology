#!/usr/bin/env python3

import argparse
import logging
import os
import pandas as pd
import sys

import brttools.convert
from brttools.convert import SCHEMA

logger = logging.getLogger(__name__)

metadata_properties_file = "metadata_properties.csv"
namespaces_file = "namespaces.csv"
resources_file = "resources.csv"
clinical_properties_file = "clinical_properties.csv"
clinical_vocabularies_file = "clinical_vocabularies.csv"
required_files = [
    metadata_properties_file,
    namespaces_file,
    resources_file,
    clinical_properties_file,
    clinical_vocabularies_file,
]
summary_file = "clinical_terms_summary.xlsx"

parser = argparse.ArgumentParser(
    description=(
        f"Validate the {required_files} specification files and generate the"
        f" summary pivot table file: {summary_file}"
    )
)
parser.add_argument(
    "-d",
    "--input_directory",
    required=True,
    help=(
        f"Validate files in the input directory {required_files}; generates "
        f"'clinical_properties_validated.csv' and 'clinical_vocabularies_validated.csv' files"
    ),
)
parser.add_argument(
    "-s",
    "--summary_file",
    help=(
        f"Merge a {summary_file} to the current specfication, creating "
        f"'clinical_properties_from_summary.csv' and 'clinical_vocabularies_from_summary.csv'"
    ),
)
parser.add_argument(
    "-v",
    "--verbose",
    dest="verbose",
    action="count",
    help="Increase verbosity (specify multiple times for more)",
)

if __name__ == "__main__":
    args = parser.parse_args()
    log_level = logging.WARNING  # default
    if args.verbose:
        if args.verbose == 1:
            log_level = logging.INFO
        elif args.verbose >= 2:
            log_level = logging.DEBUG
    logging.basicConfig(
        level=log_level,
        format="%(msecs)d:%(module)s:%(lineno)d:%(levelname)s: %(message)s",
    )
    required_files = [os.path.join(args.input_directory, f) for f in required_files]
    for f in required_files:
        if not os.path.exists(f):
            raise Exception("File not found: %s", f)

    print("Validate existing files...")
    metadata_type_field_map = brttools.convert.read_metadata_properties_file(
        os.path.join(args.input_directory, metadata_properties_file)
    )
    clinical_property_fields = metadata_type_field_map[SCHEMA.MetadataType.clinical_property]
    clinical_vocab_fields = metadata_type_field_map[SCHEMA.MetadataType.clinical_vocabulary]
    namespaces = brttools.convert.read_namespaces_file(
        os.path.join(args.input_directory, namespaces_file),
        metadata_type_field_map[SCHEMA.MetadataType.metadata_namespace]
    )
    resources = brttools.convert.read_resources_file(
        os.path.join(args.input_directory, resources_file),
        metadata_type_field_map[SCHEMA.MetadataType.metadata_resource]
    )

    print(f"Read {clinical_properties_file}")
    property_df = brttools.convert.cleanup_dataframe(
        pd.read_csv(
            clinical_properties_file, sep="\t", dtype=str, keep_default_na=False
        )
    )
    print(f"Read {clinical_vocabularies_file}")
    vocab_df = brttools.convert.cleanup_dataframe(
        pd.read_csv(
            clinical_vocabularies_file, sep="\t", dtype=str, keep_default_na=False
        )
    )
    property_df.index += 2
    vocab_df.index += 2
    print("Validate...")
    property_df, vocab_df = brttools.convert.validate_specification(
        resources,
        namespaces,
        clinical_property_fields,
        clinical_vocab_fields,
        property_df,
        vocab_df,
    )
    print("\nValidation success\n")

    if args.summary_file:
        print("Read summary file...")

        summary_dataframes = pd.read_excel(
            args.summary_file, sheet_name=None, dtype=str, keep_default_na=False
        )
        summary_dataframes = {
            k: brttools.convert.cleanup_dataframe(df)
            for k, df in summary_dataframes.items()
        }

        new_property_df, new_vocab_df = brttools.convert.read_summary(
            namespaces,
            summary_dataframes,
            clinical_property_fields,
            clinical_vocab_fields,
        )

        print("\nRead summary success\n")

        print("Merge original specification to the summary specification...")
        new_property_df = brttools.convert.merge_property_dataframes(
            property_df, new_property_df
        )
        new_vocab_df = brttools.convert.merge_vocab_dataframes(vocab_df, new_vocab_df)

        new_property_df, new_vocab_df = brttools.convert.validate_specification(
            resources,
            namespaces,
            clinical_property_fields,
            clinical_vocab_fields,
            new_property_df,
            new_vocab_df,
        )

        property_file_name, _extension = os.path.splitext(clinical_properties_file)
        output_filename = os.path.join(
            args.input_directory, f"{property_file_name}_from_summary.csv"
        )
        print("Write merged property file to %r" % output_filename)
        new_property_df.to_csv(output_filename, sep="\t", index=False)

        vocab_file_name, _extension = os.path.splitext(clinical_vocabularies_file)
        output_filename = os.path.join(
            args.input_directory, f"{vocab_file_name}_from_summary.csv"
        )
        print("Write merged vocabulary file to %r" % output_filename)
        new_vocab_df.to_csv(output_filename, sep="\t", index=False)

    else:
        print("Create summary file...")

        summary_df = brttools.convert.create_summary(
            resources, namespaces, property_df, vocab_df
        )

        property_file_name, _extension = os.path.splitext(clinical_properties_file)
        output_filename = os.path.join(
            args.input_directory, f"{property_file_name}_validated.csv"
        )
        print("Write validated property file to %r" % output_filename)
        property_df.to_csv(output_filename, sep="\t", index=False)

        vocab_file_name, _extension = os.path.splitext(clinical_vocabularies_file)
        output_filename = os.path.join(
            args.input_directory, f"{vocab_file_name}_validated.csv"
        )
        print("Write validated vocabulary file to %r" % output_filename)
        vocab_df.to_csv(output_filename, sep="\t", index=False)

        output_filename = os.path.join(
            args.input_directory, f"{property_file_name}_summary.xlsx"
        )
        print("Write summary to %r" % output_filename)
        with pd.ExcelWriter(output_filename) as writer:
            for resource_namespace, df in summary_df.items():
                df.to_excel(
                    writer, sheet_name=" - ".join(resource_namespace), index=False
                )
